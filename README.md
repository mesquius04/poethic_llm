# Building a Conversational LLM

This is a project from the Deep Learning Course. We present several experiments regarding the fine-tuning process of an LLM into a poet. Detailed information regarding datasets, architectural decisions, experiments, and results can be found in `project_report.pdf`. We hope you like it :)

To run our code, we recommend using the Google Colab environment. For the DeepSeek model, you may need to increase the computational resources of your Colab plan (or train in another environment). Keep in mind that *relative* directories and the *name and environment* chosen to save the model between both fine-tuning processes are the most sensitive points when working with our code. So please be especially careful with those aspects. For the Deep Learning subject, we will provide a SharedDrive link to our exact environment to avoid these types of problems. 

If you encounter any issues, feel free to open an Issue in this repo, and we will respond shortly.

Thank you and have a nice day :)
